{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_holidays = holidays.NL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path, quick=False):\n",
    "    allFiles = glob.glob(path + '/*.tsv')\n",
    "    bigFile = []\n",
    "    for f in tqdm(allFiles):\n",
    "        if quick==True:\n",
    "            df = pd.read_csv(f, delimiter='\\t', usecols=[\"date\", \"page\", \"ocr\", \"len\"])\n",
    "        else:\n",
    "            df = pd.read_csv(f, delimiter='\\t')\n",
    "            df['ocr'] = df['ocr'].astype(str)\n",
    "            df = df[~df['date'].str.contains('date')]  # remove double headers\n",
    "            df = df[~df['ocr'].str.contains('objecttype')]  # remove double headers\n",
    "            df['ocr'] = df['ocr'].astype(str)\n",
    "            if 'len' in df.columns:\n",
    "                pass\n",
    "            else:\n",
    "                df['len'] = df['ocr'].str.split().apply(len)\n",
    "            if 'id' in df.columns:\n",
    "                pass\n",
    "            else:\n",
    "                df['id'] = df['ocr_url'].astype(str).str.extract(r'(\\d{9})')\n",
    "        bigFile.append(df)\n",
    "    return pd.concat(bigFile)\n",
    "\n",
    "def generate_stats(df, title, freq='Y'):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df['len'] = df['len'].astype(int)\n",
    "    mean_x = df['len'].groupby(pd.Grouper(freq=freq)).describe()['mean']\n",
    "    p05 = df['len'].groupby(pd.Grouper(freq=freq)).quantile(0.05)\n",
    "    p95 = df['len'].groupby(pd.Grouper(freq=freq)).quantile(0.95)\n",
    "\n",
    "    plt.plot(mean_x)\n",
    "    plt.errorbar(mean_x.index, mean_x, yerr=[mean_x - p05, p95 - mean_x], linestyle='')\n",
    "    plt.title('Mean Length {}'.format(df['len'].mean()))\n",
    "    plt.ylabel('Total number of words')\n",
    "    plt.xlabel('Date')\n",
    "    plt.savefig('../figures/{}_{}_length.png'.format(title, type_));\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    article_count = df['ocr'].groupby(pd.Grouper(freq=freq)).count()\n",
    "    plt.plot(article_count)\n",
    "    plt.title('Mean Count {}'.format(np.mean(article_count)))\n",
    "    plt.ylabel('Articles per year')\n",
    "    plt.xlabel('Date')\n",
    "    plt.savefig('../figures/{}_{}_count.png'.format(title, type_));\n",
    "    \n",
    "    df['page'] = df['page'].astype(int)\n",
    "    '''\n",
    "    TO DO: clean up this code\n",
    "    '''\n",
    "    missing = df[df['page'] == 1].groupby(pd.Grouper(freq='D'))['page'].mean().sort_values()\n",
    "    missingdates = missing[missing.isnull()]\n",
    "    missingdates = missingdates[missingdates.index.day_name() != 'Sunday']\n",
    "    missingdates = pd.Series([date.strftime('%d-%m-%Y') for date in missingdates.index if (date in nl_holidays) == False])   \n",
    "    missingdates.to_csv('../missing_data/{}_{}_missing.csv'.format(title, type_), header=['dates'])\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "def split_years(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    for name, group in df.set_index('date').groupby(pd.Grouper(freq ='Y')):\n",
    "        group.to_csv(path + title + '_' + str(name.year) + '.tsv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'trouw'\n",
    "type_ = 'articles'\n",
    "path = '../{}/{}/'.format(title, type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_files(path, quick=True)\n",
    "generate_stats(df, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output split by years\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "for name, group in df.set_index('date').groupby(pd.Grouper(freq ='Y')):\n",
    "    group.to_csv(path + title + '_' + str(name.year) + '.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
